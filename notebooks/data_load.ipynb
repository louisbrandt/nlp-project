{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load of Data Raw or processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_save = False\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['en', 'jp','fr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_prep_data(language):\n",
    "    categories = ['dvd', 'books', 'music']\n",
    "    data = {}\n",
    "    for category in categories:\n",
    "        path_train = f'cls-acl10-unprocessed/{language}/{category}/train.review'\n",
    "        file_train = open(path_train,\"r\")\n",
    "        xml_train= file_train.read()\n",
    "        ordered_train=xmltodict.parse(xml_train)\n",
    "        train_ordered_data = ordered_train['items']['item'] # extract dictionary        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #unlabeled data\n",
    "        path_unlabeled = f'cls-acl10-unprocessed/{language}/{category}/unlabeled.review'    \n",
    "        file_unlabeled = open(path_unlabeled,\"r\")\n",
    "        xml_unlabeled= file_unlabeled.read()\n",
    "        ordered_unlabeled=xmltodict.parse(xml_unlabeled)        \n",
    "        unlabeled_ordered_data = ordered_unlabeled['items']['item'] # extract dictionary\n",
    "        \n",
    "        key_in_dict = list(train_ordered_data[0].keys())\n",
    "        #print(len(data), len(ordered_data)+len(data))\n",
    "        #len(data), len(ordered_data)+len(data)\n",
    "        i = len(data)\n",
    "        for entry in train_ordered_data:\n",
    "            #print(i)\n",
    "            keys = {j:None for j in key_in_dict}\n",
    "            data[i] = keys\n",
    "            for key, value in entry.items():\n",
    "                #print(i, '\\n', value)\n",
    "                data[i][key] = value\n",
    "            i+=1\n",
    "            \n",
    "        for entry in unlabeled_ordered_data:\n",
    "            #print(i)\n",
    "            keys = {j:None for j in key_in_dict}\n",
    "            data[i] = keys\n",
    "            for key, value in entry.items():\n",
    "                #print(i, '\\n', value)\n",
    "                data[i][key] = value\n",
    "            i+=1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prepped_data = {}\n",
    "for lang in languages:\n",
    "    train_prepped_data[lang] = train_prep_data(lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prep_data(language):\n",
    "    categories = ['dvd', 'books', 'music']\n",
    "    data = {}\n",
    "    for category in categories:\n",
    "        path_train = f'cls-acl10-unprocessed/{language}/{category}/test.review'\n",
    "\n",
    "        fileptr = open(path_train,\"r\")\n",
    "        xml_content= fileptr.read()\n",
    "        my_ordered_dict=xmltodict.parse(xml_content)\n",
    "        \n",
    "        ordered_data = my_ordered_dict['items']['item'] # extract dictionary\n",
    "\n",
    "        \n",
    "        key_in_dict = list(ordered_data[0].keys())\n",
    "        #print(len(data), len(ordered_data)+len(data))\n",
    "        #len(data), len(ordered_data)+len(data)\n",
    "        i = len(data)\n",
    "        for entry in ordered_data:\n",
    "            #print(i)\n",
    "            keys = {j:None for j in key_in_dict}\n",
    "            data[i] = keys\n",
    "            for key, value in entry.items():\n",
    "                #print(i, '\\n', value)\n",
    "                data[i][key] = value\n",
    "            i+=1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prepped_data = {}\n",
    "for lang in languages:\n",
    "    test_prepped_data[lang] = test_prep_data(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_save == True:\n",
    "    import json\n",
    "\n",
    "    with open(f'data/train/data_train.json', 'w') as file:\n",
    "        json.dump(train_prepped_data, file)\n",
    "    with open(f'data/test/data_test.json', 'w') as file:\n",
    "        json.dump(test_prepped_data, file)\n",
    "else:\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5d0bf2a609bcd5bd5a8e5e08d20ae0cc24fb4a14b1503a2d49e124dfb79944f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
