{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating 'all_data' dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(language):\n",
    "    with open(f'../../models/{language}_w2v.pickle', 'rb') as f:\n",
    "        w2v = pickle.load(f)\n",
    "\n",
    "    # Turn vocab in to mapping dict:\n",
    "    word_mapping = w2v.wv.key_to_index\n",
    "\n",
    "    # Use mapping dict to retrieve all embeddings and generate the embedding matrix\n",
    "    embedding_matrix = np.zeros((len(word_mapping), 200)) # d = 200\n",
    "    \n",
    "    row = 0\n",
    "    for word in word_mapping:\n",
    "        embedding_matrix[row] = w2v.wv.get_vector(word_mapping[word]).reshape(1,-1)\n",
    "        row+=1\n",
    "    return torch.from_numpy(embedding_matrix), word_mapping\n",
    "\n",
    "def get_numeric_corpus(corpus,lookup):\n",
    "    input_x = []\n",
    "    for sequence in corpus:\n",
    "        seq = []\n",
    "        for word in sequence:\n",
    "            seq.append(lookup[word])\n",
    "        input_x.append(seq)\n",
    "    return input_x\n",
    "\n",
    "def padding(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features\n",
    "\n",
    "def compute_seq_len():\n",
    "    return 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(lang,split,lookup):\n",
    "    with open(f'../../data/amazon_reviews/{split}/processed_data/{split}_tokens_{lang}.pickle', 'rb') as f:\n",
    "        corp = pickle.load(f)\n",
    "    ncorp = get_numeric_corpus(corp,lookup)\n",
    "    padded = padding(ncorp, compute_seq_len())\n",
    "    with open(f'../../data/amazon_reviews/{split}/processed_data/y_{split}_{lang}.pickle', 'rb') as y:\n",
    "        ys = pickle.load(y)\n",
    "    return corp, ncorp, padded, np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dd2():\n",
    "    return dict()\n",
    "def dd():\n",
    "    return defaultdict(dd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = defaultdict(dd)\n",
    "embedding_dict = defaultdict(dd)\n",
    "languages = ['en','fr','jp']\n",
    "splits = ['train','test'] # can try validation\n",
    "steps = ['corpus', 'ncorp', 'padded','y']\n",
    "\n",
    "for lang in tqdm(languages):\n",
    "    embedding_dict[lang]['matrix'], embedding_dict[lang]['lookup'] = create_embedding_matrix(lang)\n",
    "\n",
    "    for split in tqdm(splits,leave=False):\n",
    "        data[lang][split][steps[0]], data[lang][split][steps[1]], data[lang][split][steps[2]], data[lang][split][steps[3]]  = get_data(lang, split, embedding_dict[lang]['lookup'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in data.keys():\n",
    "    for s in data[l].keys():\n",
    "        for d in data[l][s]:\n",
    "            print(l,s, d, np.shape(data[l][s][d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../data/amazon_reviews/all_data.pickle','wb')as f:\n",
    "    pickle.dump(data,f)\n",
    "\n",
    "with open(f'../../data/amazon_reviews/mono_lang_embeddings.pickle','wb')as x:\n",
    "    pickle.dump(embedding_dict,x)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
